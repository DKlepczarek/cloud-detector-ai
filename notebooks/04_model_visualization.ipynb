{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5b8e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9e9b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from src.data_loader import get_data_generators\n",
    "\n",
    "MODEL_PATH = '../models/cloud_model_best.h5'\n",
    "DATA_DIR = '../data/raw'\n",
    "IMG_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70b5c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Data and Model\n",
    "print(\"--- Loading Validation Data and Model ---\")\n",
    "# shuffle=False is crucial here to match predictions with ground truth labels\n",
    "_, val_gen = get_data_generators(DATA_DIR, img_size=IMG_SIZE, batch_size=32)\n",
    "val_gen.shuffle = False\n",
    "val_gen.reset()\n",
    "\n",
    "print(f\"Loading model from: {MODEL_PATH}\")\n",
    "model = tf.keras.models.load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f385047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Generate Predictions \n",
    "print(\"--- Generating Predictions ---\")\n",
    "Y_pred_probs = model.predict(val_gen, verbose=0)\n",
    "y_pred = np.argmax(Y_pred_probs, axis=1) \n",
    "y_true = val_gen.classes                 \n",
    "class_names = list(val_gen.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf66b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Identify Error Indices\n",
    "errors = np.where(y_pred != y_true)[0]\n",
    "print(f\"Number of misclassified images: {len(errors)} out of {len(y_true)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2825a2e5",
   "metadata": {},
   "source": [
    "Visualization of top mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe321a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mistakes(num_to_show=5):\n",
    "    \"\"\"\n",
    "    Visualizes the 'worst' mistakes: images where the model was \n",
    "    highly confident but wrong.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve confidence scores for incorrect decisions\n",
    "    error_confidences = []\n",
    "    for i in errors:\n",
    "        confidence = Y_pred_probs[i][y_pred[i]]\n",
    "        error_confidences.append((confidence, i))\n",
    "    \n",
    "    # Sort in descending order (highest confidence mistakes first)\n",
    "    error_confidences.sort(key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    # Select top N errors\n",
    "    top_errors = error_confidences[:num_to_show]\n",
    "\n",
    "    if not top_errors:\n",
    "        print(\"No errors found! The model is perfect on this dataset.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(15, 6 * num_to_show))\n",
    "    \n",
    "    for idx, (conf, img_idx) in enumerate(top_errors):\n",
    "        # Calculate batch index to retrieve the specific image\n",
    "        batch_idx = img_idx // 32\n",
    "        in_batch_idx = img_idx % 32\n",
    "        \n",
    "        # Manually extract image from the generator\n",
    "        # Note: This might take a moment as we iterate through the generator\n",
    "        val_gen.reset()\n",
    "        for _ in range(batch_idx + 1):\n",
    "            batch_imgs, batch_labels = next(val_gen)\n",
    "            \n",
    "        img = batch_imgs[in_batch_idx]\n",
    "        true_label = class_names[y_true[img_idx]]\n",
    "        pred_label = class_names[y_pred[img_idx]]\n",
    "        \n",
    "        # Plotting\n",
    "        plt.subplot(num_to_show, 1, idx + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Title with error details\n",
    "        title_text = (f\"MISTAKE #{idx+1}\\n\"\n",
    "                      f\"Ground Truth: {true_label} | Prediction: {pred_label}\\n\"\n",
    "                      f\"Model Confidence: {conf:.2%}\")\n",
    "        \n",
    "        plt.title(title_text, fontsize=14, color='red', fontweight='bold')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run the visualization\n",
    "plot_mistakes(num_to_show=5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
