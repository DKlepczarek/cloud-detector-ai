{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4f0d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd62756",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('..'))\n",
    "from src.data_loader import get_data_generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325eb400",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = '../models/cloud_model_best.h5'\n",
    "DATA_DIR = '../data/raw'\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960a76b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- 1. Preparing validation environment ---\")\n",
    "\n",
    "_, val_gen = get_data_generators(DATA_DIR, img_size=IMG_SIZE, batch_size=BATCH_SIZE)\n",
    "val_gen.shuffle = False\n",
    "val_gen.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c413ff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"--- 2. Model loading: {MODEL_PATH} ---\")\n",
    "model = tf.keras.models.load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4b5302",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- 3. Making predictions ---\")\n",
    "\n",
    "Y_pred_probs = model.predict(val_gen, verbose=1)\n",
    "y_pred = np.argmax(Y_pred_probs, axis=1)\n",
    "y_true = val_gen.classes\n",
    "class_names = list(val_gen.class_indices.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf0f84f",
   "metadata": {},
   "source": [
    "Quantitative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b1e7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Evaluation raport on cloud classification model:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Basic metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# top-2 accuracy\n",
    "top2_acc = tf.keras.metrics.top_k_categorical_accuracy(\n",
    "    tf.keras.utils.to_categorical(y_true), Y_pred_probs, k=2\n",
    ")\n",
    "print(f\"Top-2 Accuracy: {np.mean(top2_acc):.2%}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\n Classification Report (Precision, Recall, F1-Score):\")\n",
    "report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "print(df_report.round(2))\n",
    "df_report.to_csv('evaluation_metrics.csv')\n",
    "\n",
    "# ROC AUC Score (Multiclass)\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_true)\n",
    "y_true_binary = lb.transform(y_true)\n",
    "\n",
    "roc_auc = roc_auc_score(y_true_binary, Y_pred_probs, multi_class='ovr', average='weighted')\n",
    "print(f\"\\n Weighted ROC AUC Score: {roc_auc:.4f} (Ideally = 1.0)\")\n",
    "print(\"-\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fca4bd",
   "metadata": {},
   "source": [
    "Statistical visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae0b34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Confusion Matrix (Heatmap)\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Ground Truth')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64594504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: ROC Curves for each class\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, class_name in enumerate(class_names):\n",
    "    fpr, tpr, _ = roc_curve(y_true_binary[:, i], Y_pred_probs[:, i])\n",
    "    roc_auc_class = auc(fpr, tpr)\n",
    "\n",
    "    plt.plot(fpr, tpr, label=f'{class_name} (AUC = {roc_auc_class:.2f})')\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Guess')\n",
    "\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multiclass ROC Curves (Receiver Operating Characteristic)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
